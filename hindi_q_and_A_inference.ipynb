{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hindi_q_and_A_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "580mNk5AJ1Hd",
        "outputId": "47ba7caf-bee3-4243-98d9-ce00c00bc473"
      },
      "source": [
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "9ksB2ItqIter"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRPEZu1bJ1Bt"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenizers"
      ],
      "metadata": {
        "id": "sTwHHcH64l4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLL-UddA3fde",
        "outputId": "88f4489a-a3ed-4be3-8011-d422e030f5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4'\n",
        "bert_layer = hub.KerasLayer(tfhub_handle_encoder,trainable=True)"
      ],
      "metadata": {
        "id": "7zqWZk6XFCLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNcVspAuXQKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d988b4a-60b6-4c6b-938d-1f4652c2d23a"
      },
      "source": [
        "import time\n",
        "t1=time.time()\n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4'\n",
        "bert_layer = hub.KerasLayer(tfhub_handle_encoder,trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file)\n",
        "print(time.time()-t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.43530631065369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9F0ymjUZXGM",
        "outputId": "5708698a-f0c4-4ad5-82f0-7fb878b8eca2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQ0ALL5RRUC"
      },
      "source": [
        "class Sample:\n",
        "    def __init__(self, question, context, start_char_idx=None, answer_text=None, answer_exist=1):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.answer_exist = answer_exist\n",
        "        self.skip = False\n",
        "        self.start_token_idx = -1\n",
        "        self.end_token_idx = -1\n",
        "\n",
        "    def preprocess(self):\n",
        "        # tokenize context and question\n",
        "        tokenized_context = tokenizer.encode(self.context)\n",
        "        tokenized_question = tokenizer.encode(self.question)\n",
        "        \n",
        "        # if this is validation or training sample, preprocess answer\n",
        "        if self.answer_text is not None:\n",
        "            # check if end character index is in the context\n",
        "            end_char_idx = self.start_char_idx + len(self.answer_text)\n",
        "            if end_char_idx >= len(self.context):\n",
        "                self.skip = True\n",
        "                return\n",
        "        \n",
        "            # mark all the character indexes in context that are also in answer     \n",
        "            is_char_in_ans = [0] * len(self.context)\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\n",
        "                is_char_in_ans[idx] = 1\n",
        "            ans_token_idx = []\n",
        "        \n",
        "            # find all the tokens that are in the answers\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\n",
        "                    ans_token_idx.append(idx)\n",
        "        \n",
        "            if len(ans_token_idx) == 0:\n",
        "                self.skip = True\n",
        "                return\n",
        "        \n",
        "            # get start and end token indexes\n",
        "            if self.answer_exist == 1:\n",
        "                self.start_token_idx = ans_token_idx[0]\n",
        "                self.end_token_idx = ans_token_idx[-1]\n",
        "            else:\n",
        "                self.start_token_idx = 0\n",
        "                self.end_token_idx = 0\n",
        "                \n",
        "        # create inputs as usual\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        \n",
        "        # add padding if necessary\n",
        "        if padding_length > 0:\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "        \n",
        "        self.input_word_ids = input_ids\n",
        "        self.input_type_ids = token_type_ids\n",
        "        self.input_mask = attention_mask\n",
        "        self.context_token_to_char = tokenized_context.offsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-46fHcFAJ6Lk"
      },
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4'\n",
        "model_name = 'bert-chaii'\n",
        "model_name = 'bert-chaii'\n",
        "max_seq_length = 512\n",
        "\n",
        "word_sep = ' '\n",
        "max_word_len = 128\n",
        "word_overlap = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqEILfRGJj50"
      },
      "source": [
        "def create_bert_inputs(samples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "\n",
        "    for item in samples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    \n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGmSNqLpQpB5"
      },
      "source": [
        "def make_spans(question, context, answer_start=None, answer_text=None):\n",
        "    span_texts, words = make_span_texts(context)\n",
        "    spans = []\n",
        "    total_char_len = 0\n",
        "    span_no = 0\n",
        "\n",
        "    for s in span_texts:\n",
        "        span_context = word_sep.join(s)\n",
        "        span_char_len = len(span_context)\n",
        "        span_answer_start = 0\n",
        "        span_answer_exist = 0\n",
        "        \n",
        "        if answer_text is not None:\n",
        "            if (answer_start >= total_char_len and  answer_start < (total_char_len + span_char_len)): # Answer exist\n",
        "                span_answer_exist = 1\n",
        "                if span_no > 0:\n",
        "                    span_answer_start = answer_start - total_char_len\n",
        "                else:\n",
        "                    span_answer_start =  answer_start # for span 0\n",
        "            \n",
        "        span = [question, span_context, span_answer_start, answer_text, span_answer_exist]\n",
        "        spans.append(span)\n",
        "        \n",
        "        total_char_len = total_char_len + span_char_len\n",
        "        span_no = span_no + 1\n",
        "\n",
        "    return spans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx6FgpvcQqQp"
      },
      "source": [
        "def make_span_texts(text):\n",
        "    words = text.split(word_sep)\n",
        "    nwords = len(words)\n",
        "    remainder = nwords % max_word_len\n",
        "    nspans = int((nwords - remainder) / max_word_len) + 1\n",
        "    spans = []\n",
        "\n",
        "    for x in range(nspans):\n",
        "        start = x*(max_word_len-word_overlap)\n",
        "        end = start + max_word_len\n",
        "        if(end > nwords): end = nwords\n",
        "        span = words[start:end]\n",
        "        spans.append(span)\n",
        "\n",
        "    return spans, words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7_XFeGbJbGe"
      },
      "source": [
        "def chaii_test_data(ques, text):\n",
        "    samples = []\n",
        "    question = ques\n",
        "    context = text\n",
        "    spans = make_spans(question, context)\n",
        "    for s in spans:\n",
        "        s = Sample(s[0], s[1])\n",
        "        s.preprocess()\n",
        "        samples.append(s)\n",
        "            \n",
        "    return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXlTOhMTVDCw",
        "outputId": "46461aaa-8eb9-4b5c-f99d-6c52dfa993ca"
      },
      "source": [
        "!unzip /content/drive/MyDrive/bert-chaii.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/bert-chaii.zip\n",
            "   creating: bert-chaii/assets/\n",
            "  inflating: bert-chaii/assets/vocab.txt  \n",
            "  inflating: bert-chaii/keras_metadata.pb  \n",
            "  inflating: bert-chaii/saved_model.pb  \n",
            "   creating: bert-chaii/variables/\n",
            "  inflating: bert-chaii/variables/variables.data-00000-of-00001  \n",
            "  inflating: bert-chaii/variables/variables.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzH92LC4UePQ"
      },
      "source": [
        "model = tf.keras.models.load_model(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5644aKaF9EG"
      },
      "source": [
        "def testModel(ques,text):\n",
        "    \n",
        "    #model = tf.keras.models.load_model(model_name)\n",
        "    test_samples = chaii_test_data(ques,text)\n",
        "    test_samples = [x for x in test_samples if x.skip == False]\n",
        "    xt, _ = create_bert_inputs(test_samples)\n",
        "    \n",
        "    pred_start, pred_end = model.predict(xt)\n",
        "    \n",
        "    for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "        \n",
        "        test_sample = test_samples[idx]\n",
        "        offsets = test_sample.context_token_to_char\n",
        "        start = np.argmax(start)\n",
        "        end = np.argmax(end)\n",
        "        pred_ans = None\n",
        "        \n",
        "        if start >= end : continue\n",
        "        if start >= len(offsets): continue\n",
        "\n",
        "        pred_char_start = offsets[start][0]\n",
        "        if end < len(offsets):\n",
        "            pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "        else:\n",
        "            pred_ans = test_sample.context[pred_char_start:]\n",
        "        #print(\"here in test model\")\n",
        "        #print(\"Q: \" + test_sample.question)\n",
        "        #print(\"A: \" + pred_ans)\n",
        "        return pred_ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xubyhM2CL0bH"
      },
      "source": [
        "Context:    \n",
        "सीऐटल (अंग्रेजी: Seattle) अमेरिका के वाशिंगटन राज्य का एक प्रमुख शहर है। यह वाशिंगटन राज्य का सबसे बड़ा शहर होने के साथ-साथ वहाँ का प्रमुख बन्दरगाह भी है। यह प्रशान्त महासागर तथा लेक वौशिन्ग्टन के बीच स्थित है। कनाडा की सीमा यहाँ से केवल १६० किलोमीटर दूर है। अप्रैल २००९ में यहाँ की आबादी लगभग ६१७०० थी।पाइक प्लेस मार्केट यहाँ की बड़ी मशहूर सब्जी मंडी है। पर्य्टक एवं निवासी रोज फल, सब्जियाँ, फूल, मछली आदी ख्ररीदनें यहाँ हजारों की तादाद् में आते हैं।मानव यहाँ कम-से-कम ४००० र्वषों से बसा हुआ है। गोरों का आगमन सन १८५१ में शुरु हुआ। आर्थ्रर डेन्नी तथा उनके साथियों ने सबसे पह्ली बस्ती बसायी जिसका नाम न्यू यॉर्क-ऍल्काइ रखा गया। सन १८५३ में दुवामिश तथा सुवामिश कबीलों के सरदार सिआलह को सम्मानित करने के लिये बस्ती का नाम सिऐटल रखा गया।श्रेणी:अमेरिका के शहर\n",
        "\n",
        "Question:     \n",
        "सीटल शहर कहाँ स्थित है?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoGe2QHwYWA3",
        "outputId": "6cc8487e-deb9-414c-bf6b-88a5cf615de5"
      },
      "source": [
        "testModel(\"सीटल शहर कहाँ स्थित है?\",\"सीऐटल (अंग्रेजी: Seattle) अमेरिका के वाशिंगटन राज्य का एक प्रमुख शहर है। यह वाशिंगटन राज्य का सबसे बड़ा शहर होने के साथ-साथ वहाँ का प्रमुख बन्दरगाह भी है। यह प्रशान्त महासागर तथा लेक वौशिन्ग्टन के बीच स्थित है। कनाडा की सीमा यहाँ से केवल १६० किलोमीटर दूर है। अप्रैल २००९ में यहाँ की आबादी लगभग ६१७०० थी।पाइक प्लेस मार्केट यहाँ की बड़ी मशहूर सब्जी मंडी है। पर्य्टक एवं निवासी रोज फल, सब्जियाँ, फूल, मछली आदी ख्ररीदनें यहाँ हजारों की तादाद् में आते हैं।मानव यहाँ कम-से-कम ४००० र्वषों से बसा हुआ है। गोरों का आगमन सन १८५१ में शुरु हुआ। आर्थ्रर डेन्नी तथा उनके साथियों ने सबसे पह्ली बस्ती बसायी जिसका नाम न्यू यॉर्क-ऍल्काइ रखा गया। सन १८५३ में दुवामिश तथा सुवामिश कबीलों के सरदार सिआलह को सम्मानित करने के लिये बस्ती का नाम सिऐटल रखा गया।श्रेणी:अमेरिका के शहर\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: सीटल शहर कहाँ स्थित है?\n",
            "A: प्रशान्त महासागर तथा लेक वौशिन्ग्टन के बीच\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onbh-UkAMNev"
      },
      "source": [
        "Context:    \n",
        "पैटन मैनिंग दो अलग-अलग टीमों को मल्टीपल सुपर बाउल में लीड लड़ने वाले पहले क्वार्टरबैक बने। वह 39 में उम्र में एक सुपर बाउल खेलने वाले सबसे अधिक उम्र के क्वार्टरबैक भी हैं। पिछला रिकॉर्ड जॉन एलवे के नाम था, जिन्होंने 38 की उम्र में सुपर बाउल XXXIII जीतने में ब्रोंकोस का नेतृत्व किया और वर्तमान में डेनवर के फुटबॉल संचालन के कार्यकारी उपाध्यक्ष और महाप्रबंधक हैं।\n",
        "\n",
        "Question:     \n",
        "सुपर बाउल में खेलने वाले सबसे अधिक उम्र के क्वार्टरबैक होने का रिकॉर्ड पहले किसके पास था?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVG_EMt3Sp7I",
        "outputId": "cd8b256e-e9f5-49ea-a76c-323a11c5c0d7"
      },
      "source": [
        "testModel(\"सुपर बाउल में खेलने वाले सबसे अधिक उम्र के क्वार्टरबैक होने का रिकॉर्ड पहले किसके पास था?\",\"पैटन मैनिंग दो अलग-अलग टीमों को मल्टीपल सुपर बाउल में लीड लड़ने वाले पहले क्वार्टरबैक बने। वह 39 में उम्र में एक सुपर बाउल खेलने वाले सबसे अधिक उम्र के क्वार्टरबैक भी हैं। पिछला रिकॉर्ड जॉन एलवे के नाम था, जिन्होंने 38 की उम्र में सुपर बाउल XXXIII जीतने में ब्रोंकोस का नेतृत्व किया और वर्तमान में डेनवर के फुटबॉल संचालन के कार्यकारी उपाध्यक्ष और महाप्रबंधक हैं।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: सुपर बाउल में खेलने वाले सबसे अधिक उम्र के क्वार्टरबैक होने का रिकॉर्ड पहले किसके पास था?\n",
            "A: पैटन मैनिंग\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLdDmKcWMn39"
      },
      "source": [
        "Context:    \n",
        "जैसा कि हाउस ऑफ कॉमन्स में, कई योग्यताएं MSP होने के लिए लागू होती हैं। ऐसी योग्यताएं हाउस ऑफ कॉमन्स डिसक्वालिफिकेशन एक्ट 1975 और ब्रिटिश नेशनलिटी एक्ट 1981 के तहत पेश की गई थी। विशेष रूप से, सदस्यों को 18 से अधिक उम्र का होना चाहिए और यूनाइटेड किंगडम, आयरलैंड गणराज्य, राष्ट्रमंडल देशों में से एक देश, ब्रिटिश विदेशी क्षेत्र का नागरिक, या ब्रिटेन में एक यूरोपीय संघ का निवासी होना चाहिए। पुलिस और सशस्त्र बलों के सदस्य को स्कॉटिश संसद में निर्वाचित MSP के रूप में बैठने से अयोग्य ठहराया जाता है, और इसी तरह, सिविल सेवकों और विदेशी विधानसभाओं के सदस्यों को अयोग्य घोषित किया जाता है। एक व्यक्ति स्कॉटिश संसद में नहीं बैठ सकता है यदि उसे मानसिक स्वास्थ्य (देखभाल और उपचार) (स्कॉटलैंड) अधिनियम 2003 की शर्तों के तहत पागल माना जाता है।\n",
        "\n",
        "Question:      \n",
        "हाउस ऑफ कॉमन्स के साथ MSP का हिस्सा क्या है?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtSuTp-FzzpC",
        "outputId": "3a82dfd2-06f3-4d46-906f-a95fc699e03f"
      },
      "source": [
        "testModel(\"हाउस ऑफ कॉमन्स के साथ MSP का हिस्सा क्या है?\",\"जैसा कि हाउस ऑफ कॉमन्स में, कई योग्यताएं MSP होने के लिए लागू होती हैं। ऐसी योग्यताएं हाउस ऑफ कॉमन्स डिसक्वालिफिकेशन एक्ट 1975 और ब्रिटिश नेशनलिटी एक्ट 1981 के तहत पेश की गई थी। विशेष रूप से, सदस्यों को 18 से अधिक उम्र का होना चाहिए और यूनाइटेड किंगडम, आयरलैंड गणराज्य, राष्ट्रमंडल देशों में से एक देश, ब्रिटिश विदेशी क्षेत्र का नागरिक, या ब्रिटेन में एक यूरोपीय संघ का निवासी होना चाहिए। पुलिस और सशस्त्र बलों के सदस्य को स्कॉटिश संसद में निर्वाचित MSP के रूप में बैठने से अयोग्य ठहराया जाता है, और इसी तरह, सिविल सेवकों और विदेशी विधानसभाओं के सदस्यों को अयोग्य घोषित किया जाता है। एक व्यक्ति स्कॉटिश संसद में नहीं बैठ सकता है यदि उसे मानसिक स्वास्थ्य (देखभाल और उपचार) (स्कॉटलैंड) अधिनियम 2003 की शर्तों के तहत पागल माना जाता है।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: हाउस ऑफ कॉमन्स के साथ MSP का हिस्सा क्या है?\n",
            "A: कई योग्यताए\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvAeI9QgNBQ-"
      },
      "source": [
        "Context:   \n",
        "उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र कहां है जिसके लिए तनाव-टेंसर की गणना की जा रही है। इस नियम-निष्ठता में दबाव की शर्तें शामिल होती हैं जो क्रॉस-सेक्शनल क्षेत्र (टैंसर के मैट्रिक्स विकर्ण) के साथ-साथ कतरनी शर्तों के साथ सामान्य रूप से कार्य करती हैं और जो क्रॉस-सेक्शनल क्षेत्र (ऑफ-डायमेंशनल एलिमेंट्स) के समानांतर कार्य करती हैं। तनाव टेंसर बलों के कारण होता है जो सभी तनावों (विकृतियों) का कारण बनता है जिसमें तन्य तनाव और संपीडन भी शामिल हैं ।:133–134:38-1–38-11\n",
        "\n",
        "Question:    \n",
        "आयतन में क्षेत्र की गणना करते समय दबाव की क्या शर्तें शामिल हैं?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqctTOHL2eIR",
        "outputId": "d1859cf8-2cdb-4cc6-92e6-e17ace760b8b"
      },
      "source": [
        "testModel(\"आयतन में क्षेत्र की गणना करते समय दबाव की क्या शर्तें शामिल हैं?\",\"उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र कहां है जिसके लिए तनाव-टेंसर की गणना की जा रही है। इस नियम-निष्ठता में दबाव की शर्तें शामिल होती हैं जो क्रॉस-सेक्शनल क्षेत्र (टैंसर के मैट्रिक्स विकर्ण) के साथ-साथ कतरनी शर्तों के साथ सामान्य रूप से कार्य करती हैं और जो क्रॉस-सेक्शनल क्षेत्र (ऑफ-डायमेंशनल एलिमेंट्स) के समानांतर कार्य करती हैं। तनाव टेंसर बलों के कारण होता है जो सभी तनावों (विकृतियों) का कारण बनता है जिसमें तन्य तनाव और संपीडन भी शामिल हैं ।:133–134:38-1–38-11\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: आयतन में क्षेत्र की गणना करते समय दबाव की क्या शर्तें शामिल हैं?\n",
            "A: नियम-निष्ठता\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTkoZdYcNRFd"
      },
      "source": [
        "Context:   \n",
        "उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र कहां है जिसके लिए तनाव-टेंसर की गणना की जा रही है। इस नियम-निष्ठता में दबाव की शर्तें शामिल होती हैं जो क्रॉस-सेक्शनल क्षेत्र (टैंसर के मैट्रिक्स विकर्ण) के साथ-साथ कतरनी शर्तों के साथ सामान्य रूप से कार्य करती हैं और जो क्रॉस-सेक्शनल क्षेत्र (ऑफ-डायमेंशनल एलिमेंट्स) के समानांतर कार्य करती हैं। तनाव टेंसर बलों के कारण होता है जो सभी तनावों (विकृतियों) का कारण बनता है जिसमें तन्य तनाव और संपीडन भी शामिल हैं ।:133–134:38-1–38-11\n",
        "\n",
        "Question:   \n",
        "सामान्य ताकतों से क्या जुड़ा है?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lkcUPZR2zd6",
        "outputId": "9cfb6d9e-43a5-4d80-b211-bedaf069b6ea"
      },
      "source": [
        "testModel(\"सामान्य ताकतों से क्या जुड़ा है?\",\"उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र कहां है जिसके लिए तनाव-टेंसर की गणना की जा रही है। इस नियम-निष्ठता में दबाव की शर्तें शामिल होती हैं जो क्रॉस-सेक्शनल क्षेत्र (टैंसर के मैट्रिक्स विकर्ण) के साथ-साथ कतरनी शर्तों के साथ सामान्य रूप से कार्य करती हैं और जो क्रॉस-सेक्शनल क्षेत्र (ऑफ-डायमेंशनल एलिमेंट्स) के समानांतर कार्य करती हैं। तनाव टेंसर बलों के कारण होता है जो सभी तनावों (विकृतियों) का कारण बनता है जिसमें तन्य तनाव और संपीडन भी शामिल हैं ।:133–134:38-1–38-11\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: सामान्य ताकतों से क्या जुड़ा है?\n",
            "A: दबाव की शर्त\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prK-IF7gNvo5"
      },
      "source": [
        "Context:   \n",
        "पूंजीवाद, अभिजात वर्ग और साम्राज्यवाद के बीच संबंध लंबे समय से इतिहासकारों और राजनीतिक सिद्धांतकारों के बीच बहस के मुद्दे रहे हैं। इस बहस के अधिकांश हिस्से के अगुआ जे. ए. होबसन (1858-1940), जोसेफ शम्पेटर (1883-1950), थोरस्टीन वेबलिन (1857-1929) और नॉर्मन एंगेल (1872-1967) जैसे सिद्धांतकार थे। जबकि ये गैर-मार्क्सवादी लेखक प्रथम विश्व युद्ध से पहले सबसे अधिक सफल थे, वे युद्ध काल के वर्षों में सक्रिय रहे। उनके संयुक्त कार्य ने साम्राज्यवाद के अध्ययन और इसके यूरोप पर प्रभाव की जानकारी दी, साथ ही साथ संयुक्त राज्य अमेरिका में 1950 के दशक से सैन्य-राजनीतिक संकुल के उदय की भावना में योगदान दिया। हॉबसन ने तर्क दिया कि घरेलू सामाजिक सुधार साम्राज्यवाद की अंतरराष्ट्रीय बीमारी को उसकी आर्थिक नींव को हटाकर ठीक कर सकते हैं। हॉब्सन ने कहा कि कराधान के माध्यम से राज्य का हस्तक्षेप व्यापक खपत को बढ़ावा दे सकता है, धन का सृजन कर सकता है और एक शांतिपूर्ण, सहिष्णु, बहुध्रुवीय विश्व व्यवस्था को प्रोत्साहित कर सकता है।\n",
        "\n",
        "Question:   \n",
        "कुछ बहस के अनुसार पूंजीवाद, साम्राज्यवाद, और किस चीज़ के बीच एक संबंध है?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6KwKLEF30Jy",
        "outputId": "9e457c8a-ae3e-4576-bcb4-ae4fe5f2daa2"
      },
      "source": [
        "testModel(\"कुछ बहस के अनुसार पूंजीवाद, साम्राज्यवाद, और किस चीज़ के बीच एक संबंध है?\",\"पूंजीवाद, अभिजात वर्ग और साम्राज्यवाद के बीच संबंध लंबे समय से इतिहासकारों और राजनीतिक सिद्धांतकारों के बीच बहस के मुद्दे रहे हैं। इस बहस के अधिकांश हिस्से के अगुआ जे. ए. होबसन (1858-1940), जोसेफ शम्पेटर (1883-1950), थोरस्टीन वेबलिन (1857-1929) और नॉर्मन एंगेल (1872-1967) जैसे सिद्धांतकार थे। जबकि ये गैर-मार्क्सवादी लेखक प्रथम विश्व युद्ध से पहले सबसे अधिक सफल थे, वे युद्ध काल के वर्षों में सक्रिय रहे। उनके संयुक्त कार्य ने साम्राज्यवाद के अध्ययन और इसके यूरोप पर प्रभाव की जानकारी दी, साथ ही साथ संयुक्त राज्य अमेरिका में 1950 के दशक से सैन्य-राजनीतिक संकुल के उदय की भावना में योगदान दिया। हॉबसन ने तर्क दिया कि घरेलू सामाजिक सुधार साम्राज्यवाद की अंतरराष्ट्रीय बीमारी को उसकी आर्थिक नींव को हटाकर ठीक कर सकते हैं। हॉब्सन ने कहा कि कराधान के माध्यम से राज्य का हस्तक्षेप व्यापक खपत को बढ़ावा दे सकता है, धन का सृजन कर सकता है और एक शांतिपूर्ण, सहिष्णु, बहुध्रुवीय विश्व व्यवस्था को प्रोत्साहित कर सकता है।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here in test model\n",
            "Q: कुछ बहस के अनुसार पूंजीवाद, साम्राज्यवाद, और किस चीज़ के बीच एक संबंध है?\n",
            "A: अभिजात वर्ग\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6doPAhM9OHh9"
      },
      "source": [
        "Context:   \n",
        "8 फरवरी 2007 को, BSkyB ने अपने तीन फ्री-टू-एयर डिजिटल टेरेस्ट्रियल चैनलों को चार सब्सक्रिप्शन चैनल्स के साथ बदलने के अपने विचार की घोषणा की। यह प्रस्तावित किया गया कि ये चैनल BSkyB पोर्टफोलियो से खेल (इंग्लिश प्रीमियर लीग फुटबॉल सहित), फिल्मों, मनोरंजन और समाचार सहित कई ऑफर प्रस्तुत करेंगे। घोषणा के एक दिन बाद सेतांता स्पोर्ट्स ने पुष्टि कि यह मार्च में डिजिटल टेरेस्ट्रियल प्लेटफॉर्म पर एक सब्सक्रिप्शन सेवा के रूप में लॉन्च किया जायेगा, और उसी दिन एनटीएल की सेवाओं को वर्जिन मीडिया का नाम दिया गया। हालांकि, उद्योग के सूत्रों का मानना है कि संभावित खोए हुए विज्ञापन राजस्व के कारण, BSkyB को अपने चैनल को फ्रीव्यू से हटाने और सब्सक्रिप्शन चैनलों को बदलने की योजना बनाने पर मजबूर होना पड़ेगा।\n",
        "\n",
        "Question:  \n",
        "सेतांता स्पोर्ट्स ने एक सब्सक्रिप्शन सेवा के रूप में लॉन्च करने के लिए कब कहा ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJFzXU-04INC",
        "outputId": "757ceeab-6eeb-45fb-ac72-5be441951f1e"
      },
      "source": [
        "testModel(\"सेतांता स्पोर्ट्स ने एक सब्सक्रिप्शन सेवा के रूप में लॉन्च करने के लिए कब कहा ?\",\"8 फरवरी 2007 को, BSkyB ने अपने तीन फ्री-टू-एयर डिजिटल टेरेस्ट्रियल चैनलों को चार सब्सक्रिप्शन चैनल्स के साथ बदलने के अपने विचार की घोषणा की। यह प्रस्तावित किया गया कि ये चैनल BSkyB पोर्टफोलियो से खेल (इंग्लिश प्रीमियर लीग फुटबॉल सहित), फिल्मों, मनोरंजन और समाचार सहित कई ऑफर प्रस्तुत करेंगे। घोषणा के एक दिन बाद सेतांता स्पोर्ट्स ने पुष्टि कि यह मार्च में डिजिटल टेरेस्ट्रियल प्लेटफॉर्म पर एक सब्सक्रिप्शन सेवा के रूप में लॉन्च किया जायेगा, और उसी दिन एनटीएल की सेवाओं को वर्जिन मीडिया का नाम दिया गया। हालांकि, उद्योग के सूत्रों का मानना है कि संभावित खोए हुए विज्ञापन राजस्व के कारण, BSkyB को अपने चैनल को फ्रीव्यू से हटाने और सब्सक्रिप्शन चैनलों को बदलने की योजना बनाने पर मजबूर होना पड़ेगा।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: सेतांता स्पोर्ट्स ने एक सब्सक्रिप्शन सेवा के रूप में लॉन्च करने के लिए कब कहा ?\n",
            "A: मार्च\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s1GTgTBORA4"
      },
      "source": [
        "Context:  \n",
        "एक कागज का टुकड़ा बाद में पाया गया जिसपर लूथर ने अपनाआखिरी कथन लिखा। यह कथन “हम याचक हैं” जो जर्मन में था,  के अतिरिक्त लैटिन में था।\n",
        "\n",
        "Question:   \n",
        "लूथर के द्वारा लिखा गया बाद में क्या खोजा गया?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-IVqQCl5ptK",
        "outputId": "6ad8ce9c-2b04-48a4-e4eb-270209ac38a3"
      },
      "source": [
        "testModel(\"लूथर के द्वारा लिखा गया बाद में क्या खोजा गया?\",\"एक कागज का टुकड़ा बाद में पाया गया जिसपर लूथर ने अपनाआखिरी कथन लिखा। यह कथन “हम याचक हैं” जो जर्मन में था,  के अतिरिक्त लैटिन में था।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: लूथर के द्वारा लिखा गया बाद में क्या खोजा गया?\n",
            "A: अपनाआखिरी कथन\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJzdWvZKh_T",
        "outputId": "20307846-4f26-466c-98b2-658c9e49c99f"
      },
      "source": [
        "testModel(\"लूथर के द्वारा लिखा गया बाद में क्या खोजा गया?\",\"एक कागज का टुकड़ा बाद में पाया गया जिसपर लूथर ने अपनाआखिरी कथन लिखा। यह कथन “हम याचक हैं” जो जर्मन में था,  के अतिरिक्त लैटिन में था।\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: लूथर के द्वारा लिखा गया बाद में क्या खोजा गया?\n",
            "A: अपनाआखिरी कथन\n"
          ]
        }
      ]
    }
  ]
}